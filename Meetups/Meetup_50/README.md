# 50th Vienna Deep Learning Meetup

* Date: 2023-05-04
* Venue: Bosch
* Meetup Page: https://www.meetup.com/de-DE/vienna-deep-learning-meetup/events/292574798/

Slides:
* [[PDF - VDLM, Survey, Jobs, Hot Topics](<./slides/50th Deep Learning Meetup Intro - Announcements - Hot Topics.pdf>)]
* [[PDF - Security of Machine Learning Systems](<./slides/20230504_VDLM_Security_of_ML.pdf>)]
* [[PDF - Intro to (deep) reinforcement learning](<./slides/Intro_Reinforcement_Learning_VDLM50.pdf>)]


## Details

Please join us for our next Deep Learning meetup on May 4th, hosted by Bosch!

We will have a presentation by Rudolf Mayer (SBA Research & Lecturer @ TU Wien) on Security of Machine Learning Systems - (How) Can We Get There?, followed by a networking break!

For the second part of the evening Sharwin Rezagholi (FH Technikum Wien) will provide an Intro to Reinforcement Learning & Current Developments, followed by a Hot Papers session on Latest Developments in Large Language Models by Michael Pieler (OpenBioML.org & Stability.AI)!

Hope to see you there!

Rene, for the VDLM organizers

***

Schedule

18:30 Welcome & Intro

18:40

Security of Machine Learning Systems - (How) Can We Get There?

    Rudolf Mayer, SBA Research & Lecturer @ TU Wien
    With machine learning increasingly being deployed within (semi-)autonomous systems and thus permeating our daily lives, these systems become likewise interesting for cybercriminals - trying to cause malfunctioning and/or make money with their attacks.
    While modern ML systems get close to or sometimes even surpass human capabilities on several tasks, they still make surprising mistakes, e.g., when focusing on little details in the input that are not directly relevant to the task. For example, an image classification system might learn to label images with polar bears as such because these images almost always contain also snow and ice - but not because of the polar bear itself! These intriguing properties of primarily deep learning systems can also be exploited on purpose, and systems can be tricked into predicting the wrong outcome for specific inputs (e.g., trick an authentication system to believe you are someone else who is allowed to access the resource), or generally make systems malfunction most of the time (e.g., the authentication system does not recognize anyone, and nobody can access the resource). Other attacks aim at stealing the machine learning model itself, so that the attackers can monetize it themselves.
    In this talk, we discuss the most prominent attack vectors on ML systems, how realistic they are already, and how you can make your ML training and prediction systems more secure to potentially detect and defend against those attacks.

:: Announcements & Job Openings ::

:: Break & Networking ::

20:10

Intro to (deep) reinforcement learning

    Sharwin Rezagholi, FH Technikum Wien
    Reinforcement learning (RL) empowers artificially intelligent agents to learn by interacting with their environment. Lately RL has achieved superhuman performance in complicated tasks, such as playing Go and Chess, or finding novel algorithms for fast matrix multiplication. RL is also a driving force behind ChatGPT.
    This progress relies on the marriage of reinforcement learning principles with deep neural networks. Deep RL is expected to play a crucial role in the search for general AI methods.
    This talk will introduce the basic ideas of RL, the role of deep neural networks in RL, and present some recent applications.

Hot Papers session

    Latest Developments in Large Language Models
    Michael Pieler, OpenBioML.org & Stability.AI

:: Networking ::

21:30 Wrap up & End
